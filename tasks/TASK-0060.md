<task id="TASK-0060">
<summary>Optimize performance bottlenecks for large-scale projects</summary>
<scope>
- Components: make/discovery.py, make/evaluator.py, ir/patterns.py, ir/cycles.py, cache.py, parallel.py
- Focus on algorithmic improvements and efficient data structures
</scope>
<developer>
- Profile code with cProfile to identify actual bottlenecks
- Optimize recursive directory traversal using os.scandir()
- Implement proper memoization for variable expansion
- Replace O(n²) pattern matching with efficient algorithms
- Use graph algorithms with better complexity for cycle detection
- Implement LRU cache with efficient eviction
- Parallelize independent file parsing operations
- Use generators and lazy evaluation for large datasets
- Batch file I/O operations where possible
- Consider Cython for performance-critical hot paths
</developer>
<qe>
- Benchmark with projects containing >1000 Makefiles
- Verify <10 second processing for large projects
- Test memory usage stays under 100MB for typical projects
- Validate variable expansion <1ms for typical cases
- Ensure pattern matching is O(n) not O(n²)
- Profile before and after to measure improvements
</qe>
<reviewer>
- Confirm performance improvements are measurable
- Verify optimizations don't break functionality
- Check that code remains readable despite optimizations
- Ensure memory usage is reasonable
- Validate that benchmarks are representative
</reviewer>
<tests>
- Performance benchmarks for all optimized paths
- Memory usage tests with large projects
- Regression tests to ensure correctness
- Stress tests with extreme inputs
- Profile-guided optimization verification
- Comparative benchmarks before/after optimization
</tests>
</task>